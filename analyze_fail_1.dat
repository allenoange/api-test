# [No.1] construct_wrapper.6
# In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(376)/    def construct(self, *inputs):/
funcgraph fg_6(
        %para1 : Tensor(F32)[32, 3, 32, 32]    # inputs0
        , %para2 : Tensor(U32)[32]    # inputs1
        , %para3 : Ref[Tensor(I32)][]    # step
        , %para4 : Ref[Tensor(F32)][64, 3, 3, 3]    # Conv2d_1.weight
        , %para5 : Ref[Tensor(F32)][64, 64, 3, 3]    # Conv2d_2.weight
        , %para6 : Ref[Tensor(F32)][128, 64, 3, 3]    # Conv2d_3.weight
        , %para7 : Ref[Tensor(F32)][128, 128, 3, 3]    # Conv2d_4.weight
        , %para8 : Ref[Tensor(F32)][256, 128, 3, 3]    # Conv2d_5.weight
        , %para9 : Ref[Tensor(F32)][256, 256, 3, 3]    # Conv2d_6.weight
        , %para10 : Ref[Tensor(F32)][512, 256, 3, 3]    # Conv2d_7.weight
        , %para11 : Ref[Tensor(F32)][512, 512, 3, 3]    # Conv2d_8.weight
        , %para12 : Ref[Tensor(F32)][4096, 512]    # fc1.weight
        , %para13 : Ref[Tensor(F32)][4096]    # fc1.bias
        , %para14 : Ref[Tensor(F32)][4096, 4096]    # fc2.weight
        , %para15 : Ref[Tensor(F32)][4096]    # fc2.bias
        , %para16 : Ref[Tensor(F32)][10, 4096]    # fc3.weight
        , %para17 : Ref[Tensor(F32)][10]    # fc3.bias
        , %para18 : Ref[Tensor(F32)][1]    # beta1_power
        , %para19 : Ref[Tensor(F32)][1]    # beta2_power
        , %para20 : Ref[Tensor(F32)][64, 3, 3, 3]    # moment1.Conv2d_1.weight
        , %para21 : Ref[Tensor(F32)][64, 64, 3, 3]    # moment1.Conv2d_2.weight
        , %para22 : Ref[Tensor(F32)][128, 64, 3, 3]    # moment1.Conv2d_3.weight
        , %para23 : Ref[Tensor(F32)][128, 128, 3, 3]    # moment1.Conv2d_4.weight
        , %para24 : Ref[Tensor(F32)][256, 128, 3, 3]    # moment1.Conv2d_5.weight
        , %para25 : Ref[Tensor(F32)][256, 256, 3, 3]    # moment1.Conv2d_6.weight
        , %para26 : Ref[Tensor(F32)][512, 256, 3, 3]    # moment1.Conv2d_7.weight
        , %para27 : Ref[Tensor(F32)][512, 512, 3, 3]    # moment1.Conv2d_8.weight
        , %para28 : Ref[Tensor(F32)][4096, 512]    # moment1.fc1.weight
        , %para29 : Ref[Tensor(F32)][4096]    # moment1.fc1.bias
        , %para30 : Ref[Tensor(F32)][4096, 4096]    # moment1.fc2.weight
        , %para31 : Ref[Tensor(F32)][4096]    # moment1.fc2.bias
        , %para32 : Ref[Tensor(F32)][10, 4096]    # moment1.fc3.weight
        , %para33 : Ref[Tensor(F32)][10]    # moment1.fc3.bias
        , %para34 : Ref[Tensor(F32)][64, 3, 3, 3]    # moment2.Conv2d_1.weight
        , %para35 : Ref[Tensor(F32)][64, 64, 3, 3]    # moment2.Conv2d_2.weight
        , %para36 : Ref[Tensor(F32)][128, 64, 3, 3]    # moment2.Conv2d_3.weight
        , %para37 : Ref[Tensor(F32)][128, 128, 3, 3]    # moment2.Conv2d_4.weight
        , %para38 : Ref[Tensor(F32)][256, 128, 3, 3]    # moment2.Conv2d_5.weight
        , %para39 : Ref[Tensor(F32)][256, 256, 3, 3]    # moment2.Conv2d_6.weight
        , %para40 : Ref[Tensor(F32)][512, 256, 3, 3]    # moment2.Conv2d_7.weight
        , %para41 : Ref[Tensor(F32)][512, 512, 3, 3]    # moment2.Conv2d_8.weight
        , %para42 : Ref[Tensor(F32)][4096, 512]    # moment2.fc1.weight
        , %para43 : Ref[Tensor(F32)][4096]    # moment2.fc1.bias
        , %para44 : Ref[Tensor(F32)][4096, 4096]    # moment2.fc2.weight
        , %para45 : Ref[Tensor(F32)][4096]    # moment2.fc2.bias
        , %para46 : Ref[Tensor(F32)][10, 4096]    # moment2.fc3.weight
        , %para47 : Ref[Tensor(F32)][10]    # moment2.fc3.bias
        , %para48 : Ref[Tensor(F32)][]    # learning_rate
    ) {
    %1 : Tuple[Tensor(F32),Tensor(U32)] = Primitive::MakeTuple{prim_type=1}(%para1, %para2)    #(Tensor(F32)[32, 3, 32, 32], Tensor(U32)[32]) #scope: Default
      # #[CNode]21

#------------------------> 0
    %2 = UnpackCall::unpack_call(FuncGraph::fg_22, %1)    #(Func, Tuple[Tensor(F32),Tensor(U32)])    # fg_22=construct.22 #scope: Default
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(377)/        if self.freeze:/#[CNode]23
    Primitive::Return{prim_type=1}(%2)    #(Undefined) #scope: Default
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(377)/        if self.freeze:/#[CNode]24
}
# order:
#   1: construct_wrapper.6:[CNode]23{[0]: ValueNode<UnpackCall> unpack_call, [1]: ValueNode<FuncGraph> construct.22, [2]: [CNode]21}
#   2: construct_wrapper.6:[CNode]24{[0]: ValueNode<Primitive> Return, [1]: [CNode]23}


# [No.2] UnpackCall.7
# 
funcgraph fg_7(
        %para49 : Func    # 8
        , %para50 : Tuple[Tensor(F32),Tensor(U32)]    # 9
    ) {
    %1 : Tensor(F32)[32, 3, 32, 32] = Primitive::TupleGetItem{prim_type=1}(%para50, I64(0))    #(Tuple[Tensor(F32),Tensor(U32)], I64) #scope: Default
      # #25
    %2 : Tensor(U32)[32] = Primitive::TupleGetItem{prim_type=1}(%para50, I64(1))    #(Tuple[Tensor(F32),Tensor(U32)], I64) #scope: Default
      # #26

#------------------------> 1
    %3 = %para49(%1, %2)    #(Tensor(F32)[32, 3, 32, 32], Tensor(U32)[32]) #scope: Default
      # #27
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default
      # #28
}
# order:
#   1: UnpackCall.7:27{[0]: 8, [1]: 25, [2]: 26}
#   2: UnpackCall.7:28{[0]: ValueNode<Primitive> Return, [1]: 27}


# [No.3] construct.10
# In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(376)/    def construct(self, *inputs):/
funcgraph fg_10[fg_6](
        %para51 : Tensor(F32)[32, 3, 32, 32]    # inputs0
        , %para52 : Tensor(U32)[32]    # inputs1
    ) {
    %1 : Bool = FuncGraph::fg_1(Bool(0))    #(Bool)    # fg_1=bool_.1 #scope: Default
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(377)/        if self.freeze:/#29
    %2 : Func = Primitive::Switch{prim_type=1}(%1, FuncGraph::fg_30, FuncGraph::fg_11)    #(Bool, Func, Func)    # fg_30=✓construct.30, fg_11=✗construct.11 #scope: Default
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(377)/        if self.freeze:/#[CNode]31

#------------------------> 2
    %3 = %2() #scope: Default
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(377)/        if self.freeze:/#[CNode]32
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(377)/        if self.freeze:/#[CNode]33
}
# order:
#   1: construct.10:29{[0]: ValueNode<FuncGraph> bool_.1, [1]: ValueNode<BoolImm> false}
#   2: construct.10:[CNode]31{[0]: ValueNode<Primitive> Switch, [1]: 29, [2]: ValueNode<FuncGraph> ✓construct.30, [3]: ValueNode<FuncGraph> ✗construct.11}
#   3: construct.10:[CNode]32{[0]: [CNode]31}
#   4: construct.10:[CNode]33{[0]: ValueNode<Primitive> Return, [1]: [CNode]32}


# [No.4] ✗construct.11
# In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(377)/        if self.freeze:/
funcgraph fg_11[fg_10](
) {
    %1 : Bool = FuncGraph::fg_1(Bool(0))    #(Bool)    # fg_1=bool_.1 #scope: Default
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(394)/            if self.use_grad_accumulation:/#34
    %2 : Func = Primitive::Switch{prim_type=1}(%1, FuncGraph::fg_35, FuncGraph::fg_12)    #(Bool, Func, Func)    # fg_35=✓✗construct.35, fg_12=✗✗construct.12 #scope: Default
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(394)/            if self.use_grad_accumulation:/#[CNode]36

#------------------------> 3
    %3 = %2() #scope: Default
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(394)/            if self.use_grad_accumulation:/#[CNode]37
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(394)/            if self.use_grad_accumulation:/#[CNode]38
}
# order:
#   1: ✗construct.11:loss{[0]: ValueNode<UnpackCall> unpack_call, [1]: ValueNode<FuncGraph> construct.16, [2]: [CNode]39}
#   2: ✗construct.11:[CNode]40{[0]: ValueNode<Primitive> getattr, [1]: loss, [2]: ValueNode<StringImm> dtype}
#   3: ✗construct.11:[CNode]41{[0]: ValueNode<Primitive> getattr, [1]: loss, [2]: ValueNode<StringImm> shape}
#   4: ✗construct.11:sens{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Fill, [1]: [CNode]40, [2]: [CNode]41, [3]: ValueNode<FP32Imm> 1.000000}
#   5: ✗construct.11:[CNode]42{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: sens}
#   6: ✗construct.11:grads{[0]: ValueNode<UnpackGraphPrimitive> UnpackGraph, [1]: ValueNode<FuncGraph> construct.16, [2]: [CNode]39, [3]: [CNode]42}
#   7: ✗construct.11:grads{[0]: ValueNode<DoSignaturePrimitive> S-Prim-grad, [1]: grads, [2]: [CNode]43}
#   8: ✗construct.11:grads{[0]: ValueNode<UnpackCall> unpack_call, [1]: grads, [2]: [CNode]39, [3]: [CNode]42}
#   9: ✗construct.11:grads{[0]: ValueNode<DoSignaturePrimitive> S-Prim-identity, [1]: grads}
#  10: ✗construct.11:34{[0]: ValueNode<FuncGraph> bool_.1, [1]: ValueNode<BoolImm> false}
#  11: ✗construct.11:[CNode]36{[0]: ValueNode<Primitive> Switch, [1]: 34, [2]: ValueNode<FuncGraph> ✓✗construct.35, [3]: ValueNode<FuncGraph> ✗✗construct.12}
#  12: ✗construct.11:[CNode]37{[0]: [CNode]36}
#  13: ✗construct.11:[CNode]38{[0]: ValueNode<Primitive> Return, [1]: [CNode]37}


# [No.5] ✗✗construct.12
# In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(394)/            if self.use_grad_accumulation:/
funcgraph fg_12[fg_11](
) {
    %1 : $(✗✗construct.12):Tuple[Tensor(F32),Tensor(U32)] = Primitive::MakeTuple{prim_type=1}(%para51, %para52)    #(Tensor(F32)[32, 3, 32, 32], Tensor(U32)[32]) #scope: Default
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(384)/            loss = self.freeze_nets[step](*inputs)/#[CNode]39

#------------------------> 4
    %2 = $(✗✗construct.12):UnpackCall::unpack_call(FuncGraph::fg_16, %1)    #(Func, Tuple[Tensor(F32),Tensor(U32)])    # fg_16=construct.16 #scope: Default
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(390)/            loss = self.network(*inputs)/#loss
    %3 = $(✗✗construct.12):Primitive::getattr{prim_type=1}(%2, "dtype")    #(Undefined, Undefined) #scope: Default
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(391)/            sens = F.fill(loss.dtype, loss.shape, self.sens)/#[CNode]40
    %4 = $(✗✗construct.12):Primitive::getattr{prim_type=1}(%2, "shape")    #(Undefined, Undefined) #scope: Default
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(391)/            sens = F.fill(loss.dtype, loss.shape, self.sens)/#[CNode]41
    %5 = $(✗✗construct.12):DoSignaturePrimitive::S-Prim-Fill{prim_type=1}(%3, %4, F32(1))    #(Undefined, Undefined, Undefined) #scope: Default
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(391)/            sens = F.fill(loss.dtype, loss.shape, self.sens)/#sens
    %6 = $(✗✗construct.12):DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}(%5)    #(Undefined) #scope: Default
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(392)/            grads = self.grad(self.network, self.weights)(*inputs, sens)/#[CNode]42
    %7 = $(✗✗construct.12):UnpackGraphPrimitive::UnpackGraph{prim_type=1}(FuncGraph::fg_16, %1, %6)    #(Undefined, Tuple[Tensor(F32),Tensor(U32)], Undefined)    # fg_16=construct.16 #scope: Default
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(392)/            grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %8 = $(✗✗construct.12):Primitive::MakeTuple{prim_type=1}(%para4, %para5, %para6, %para7, %para8, %para9, %para10, %para11, %para12, %para13, %para14, %para15, %para16, %para17)    #(Ref[Tensor(F32)][64, 3, 3, 3], Ref[Tensor(F32)][64, 64, 3, 3], Ref[Tensor(F32)][128, 64, 3, 3], Ref[Tensor(F32)][128, 128, 3, 3], Ref[Tensor(F32)][256, 128, 3, 3], Ref[Tensor(F32)][256, 256, 3, 3], Ref[Tensor(F32)][512, 256, 3, 3], Ref[Tensor(F32)][512, 512, 3, 3], Ref[Tensor(F32)][4096, 512], Ref[Tensor(F32)][4096], Ref[Tensor(F32)][4096, 4096], Ref[Tensor(F32)][4096], Ref[Tensor(F32)][10, 4096], Ref[Tensor(F32)][10]) #scope: Default
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(392)/            grads = self.grad(self.network, self.weights)(*inputs, sens)/#[CNode]43
    %9 = $(✗✗construct.12):DoSignaturePrimitive::S-Prim-grad{prim_type=1}(%7, %8)    #(Undefined, Undefined) #scope: Default
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(392)/            grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %10 = $(✗✗construct.12):UnpackCall::unpack_call(%9, %1, %6)    #(Undefined, Tuple[Tensor(F32),Tensor(U32)], Undefined) #scope: Default
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(392)/            grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %11 = $(✗✗construct.12):DoSignaturePrimitive::S-Prim-identity{prim_type=1}[side_effect_propagate=I64(1)](%10)    #(Undefined) #scope: Default
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(393)/            grads = self.grad_reducer(grads)/#grads
    %12 = FuncGraph::fg_44(%11)    #(Undefined)    # fg_44=construct.44 #scope: Default
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(397)/                loss = F.depend(loss, self.optimizer(grads))/#[CNode]45
    %13 = DoSignaturePrimitive::S-Prim-Depend{prim_type=1}[side_effect_propagate=I64(1)](%2, %12)    #(Undefined, Undefined) #scope: Default
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(397)/                loss = F.depend(loss, self.optimizer(grads))/#loss
    %14 = FuncGraph::fg_46(%13)    #(Undefined)    # fg_46=↓✗construct.46 #scope: Default
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(394)/            if self.use_grad_accumulation:/#[CNode]47
    Primitive::Return{prim_type=1}(%14)    #(Undefined) #scope: Default
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(394)/            if self.use_grad_accumulation:/#[CNode]48
}
# order:
#   1: ✗✗construct.12:[CNode]45{[0]: ValueNode<FuncGraph> construct.44, [1]: grads}
#   2: ✗✗construct.12:loss{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Depend, [1]: loss, [2]: [CNode]45}
#   3: ✗✗construct.12:[CNode]47{[0]: ValueNode<FuncGraph> ↓✗construct.46, [1]: loss}
#   4: ✗✗construct.12:[CNode]48{[0]: ValueNode<Primitive> Return, [1]: [CNode]47}


# [No.6] UnpackCall.13
# 
funcgraph fg_13(
        %para53 : Func    # 14
        , %para54 : Tuple[Tensor(F32),Tensor(U32)]    # 15
    ) {
    %1 : Tensor(F32)[32, 3, 32, 32] = Primitive::TupleGetItem{prim_type=1}(%para54, I64(0))    #(Tuple[Tensor(F32),Tensor(U32)], I64) #scope: Default
      # #49
    %2 : Tensor(U32)[32] = Primitive::TupleGetItem{prim_type=1}(%para54, I64(1))    #(Tuple[Tensor(F32),Tensor(U32)], I64) #scope: Default
      # #50

#------------------------> 5
    %3 = %para53(%1, %2)    #(Tensor(F32)[32, 3, 32, 32], Tensor(U32)[32]) #scope: Default
      # #51
    Primitive::Return{prim_type=1}(%3)    #(Undefined) #scope: Default
      # #52
}
# order:
#   1: UnpackCall.13:51{[0]: 14, [1]: 49, [2]: 50}
#   2: UnpackCall.13:52{[0]: ValueNode<Primitive> Return, [1]: 51}


# [No.7] construct.16
# In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(111)/    def construct(self, data, label):/
funcgraph fg_16[fg_6](
        %para55 : Tensor(F32)[32, 3, 32, 32]    # data
        , %para56 : Tensor(U32)[32]    # label
    ) {
    %1 : Tensor(F32)[32, 10] = FuncGraph::fg_53(%para55)    #(Tensor(F32)[32, 3, 32, 32])    # fg_53=construct.53 #scope: Default/network-WithLossCell
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(112)/        out = self._backbone(data)/#out

#------------------------> 6
    %2 = FuncGraph::fg_17(%1, %para56)    #(Tensor(F32)[32, 10], Tensor(U32)[32])    # fg_17=construct.17 #scope: Default/network-WithLossCell
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(113)/        return self._loss_fn(out, label)/#[CNode]54
    Primitive::Return{prim_type=1}(%2)    #(Undefined) #scope: Default/network-WithLossCell
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(113)/        return self._loss_fn(out, label)/#[CNode]55
}
# order:
#   1: construct.16:out{[0]: ValueNode<FuncGraph> construct.53, [1]: data}
#   2: construct.16:[CNode]54{[0]: ValueNode<FuncGraph> construct.17, [1]: out, [2]: label}
#   3: construct.16:[CNode]55{[0]: ValueNode<Primitive> Return, [1]: [CNode]54}


# [No.8] construct.17
# In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/loss/loss.py(516)/    def construct(self, logits, labels):/
funcgraph fg_17(
        %para57 : Tensor(F32)[32, 10]    # Φlogits
        , %para58 : Tensor(U32)[32]    # labels
    ) {
    %1 : NoneType = DoSignaturePrimitive::S-Prim-_check_is_tensor{prim_type=1}("logits", %para57, "SoftmaxCrossEntropyWithLogits")    #(String, Tensor(F32)[32, 10], String) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/loss/loss.py(517)/        _check_is_tensor('logits', logits, self.cls_name)/#[CNode]56
    %2 : NoneType = DoSignaturePrimitive::S-Prim-_check_is_tensor{prim_type=1}("labels", %para58, "SoftmaxCrossEntropyWithLogits")    #(String, Tensor(U32)[32], String) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/loss/loss.py(518)/        _check_is_tensor('labels', labels, self.cls_name)/#[CNode]57
    %3 : Tuple[NoneType*2] = Primitive::MakeTuple{prim_type=1}(%1, %2)    #(NoneType, NoneType) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/loss/loss.py(516)/    def construct(self, logits, labels):/#[CNode]58
    %4 : Tuple[NoneType*2] = Primitive::stop_gradient{prim_type=1}(%3)    #(Tuple[NoneType*2]) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/loss/loss.py(516)/    def construct(self, logits, labels):/#[CNode]59
    %5 : Bool = FuncGraph::fg_1(Bool(1))    #(Bool)    # fg_1=bool_.1 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/loss/loss.py(519)/        if self.sparse:/#60
    %6 : Func = Primitive::Switch{prim_type=1}(%5, FuncGraph::fg_18, FuncGraph::fg_61)    #(Bool, Func, Func)    # fg_18=✓construct.18, fg_61=✗construct.61 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/loss/loss.py(519)/        if self.sparse:/#[CNode]62

#------------------------> 7
    %7 = %6() #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/loss/loss.py(519)/        if self.sparse:/#[CNode]63
    %8 = Primitive::Depend{prim_type=1}[side_effect_propagate=I64(1)](%7, %4)    #(Undefined, Tuple[NoneType*2]) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/loss/loss.py(516)/    def construct(self, logits, labels):/#[CNode]64
    Primitive::Return{prim_type=1}(%8)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/loss/loss.py(516)/    def construct(self, logits, labels):/#[CNode]65
}
# order:
#   1: construct.17:[CNode]56{[0]: ValueNode<DoSignaturePrimitive> S-Prim-_check_is_tensor, [1]: ValueNode<StringImm> logits, [2]: Φlogits, [3]: ValueNode<StringImm> SoftmaxCrossEntropyWithLogits}
#   2: construct.17:[CNode]57{[0]: ValueNode<DoSignaturePrimitive> S-Prim-_check_is_tensor, [1]: ValueNode<StringImm> labels, [2]: labels, [3]: ValueNode<StringImm> SoftmaxCrossEntropyWithLogits}
#   3: construct.17:60{[0]: ValueNode<FuncGraph> bool_.1, [1]: ValueNode<BoolImm> true}
#   4: construct.17:[CNode]62{[0]: ValueNode<Primitive> Switch, [1]: 60, [2]: ValueNode<FuncGraph> ✓construct.18, [3]: ValueNode<FuncGraph> ✗construct.61}
#   5: construct.17:[CNode]63{[0]: [CNode]62}
#   6: construct.17:[CNode]65{[0]: ValueNode<Primitive> Return, [1]: [CNode]64}


# [No.9] ✓construct.18
# In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/loss/loss.py(519)/        if self.sparse:/
funcgraph fg_18[fg_17](
) {
    %1 : Bool = DoSignaturePrimitive::S-Prim-equal{prim_type=1}("none", "mean")    #(String, String) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/loss/loss.py(520)/            if self.reduction == 'mean':/#[CNode]66
    %2 : Bool = FuncGraph::fg_1(%1)    #(Bool)    # fg_1=bool_.1 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/loss/loss.py(520)/            if self.reduction == 'mean':/#[CNode]66
    %3 : Func = Primitive::Switch{prim_type=1}(%2, FuncGraph::fg_67, FuncGraph::fg_19)    #(Bool, Func, Func)    # fg_67=✓✓construct.67, fg_19=✗✓construct.19 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/loss/loss.py(520)/            if self.reduction == 'mean':/#[CNode]68

#------------------------> 8
    %4 = %3() #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/loss/loss.py(520)/            if self.reduction == 'mean':/#[CNode]69
    Primitive::Return{prim_type=1}(%4)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/loss/loss.py(520)/            if self.reduction == 'mean':/#[CNode]70
}
# order:
#   1: ✓construct.18:[CNode]66{[0]: ValueNode<DoSignaturePrimitive> S-Prim-equal, [1]: ValueNode<StringImm> none, [2]: ValueNode<StringImm> mean}
#   2: ✓construct.18:[CNode]66{[0]: ValueNode<FuncGraph> bool_.1, [1]: [CNode]66}
#   3: ✓construct.18:[CNode]68{[0]: ValueNode<Primitive> Switch, [1]: [CNode]66, [2]: ValueNode<FuncGraph> ✓✓construct.67, [3]: ValueNode<FuncGraph> ✗✓construct.19}
#   4: ✓construct.18:[CNode]69{[0]: [CNode]68}
#   5: ✓construct.18:[CNode]70{[0]: ValueNode<Primitive> Return, [1]: [CNode]69}


# [No.10] ✗✓construct.19
# In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/loss/loss.py(520)/            if self.reduction == 'mean':/
funcgraph fg_19[fg_17](
) {

#------------------------> 9
    %1 = FuncGraph::fg_20()    # fg_20=↓✓construct.20 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/loss/loss.py(520)/            if self.reduction == 'mean':/#[CNode]71
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/loss/loss.py(520)/            if self.reduction == 'mean':/#[CNode]72
}
# order:
#   1: ✗✓construct.19:[CNode]71{[0]: ValueNode<FuncGraph> ↓✓construct.20}
#   2: ✗✓construct.19:[CNode]72{[0]: ValueNode<Primitive> Return, [1]: [CNode]71}


# [No.11] ↓✓construct.20
# In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/loss/loss.py(520)/            if self.reduction == 'mean':/
funcgraph fg_20[fg_17](
) {
    %1 : Tuple[I64*2] = DoSignaturePrimitive::S-Prim-Shape{prim_type=1}(%para57)    #(Tensor(F32)[32, 10]) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/loss/loss.py(523)/            labels = self.one_hot(labels, F.shape(logits)[-1], self.on_value, self.off_value)/#[CNode]73
    %2 : I64 = DoSignaturePrimitive::S-Prim-negative{prim_type=1}(I64(1))    #(I64) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/loss/loss.py(523)/            labels = self.one_hot(labels, F.shape(logits)[-1], self.on_value, self.off_value)/#[CNode]74
    %3 : I64 = DoSignaturePrimitive::S-Prim-getitem{prim_type=1}(%1, %2)    #(Tuple[I64*2], I64) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/loss/loss.py(523)/            labels = self.one_hot(labels, F.shape(logits)[-1], self.on_value, self.off_value)/#[CNode]75

#------------------------> 10
    %4 = DoSignaturePrimitive::S-Prim-OneHot{prim_type=1}[axis=I64(-1), input_names=["indices", "depth", "on_value", "off_value"], output_names=["output"]](%para58, %3, Tensor(43)[], Tensor(43)[])    #(Tensor(U32)[32], I64, Tensor(F32)[], Tensor(F32)[]) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/loss/loss.py(523)/            labels = self.one_hot(labels, F.shape(logits)[-1], self.on_value, self.off_value)/#labels
    %5 = FuncGraph::fg_76(%4)    #(Undefined)    # fg_76=↓construct.76 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/loss/loss.py(519)/        if self.sparse:/#[CNode]77
    Primitive::Return{prim_type=1}(%5)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file /home/ts/miniconda3/envs/mindspore/lib/python3.7/site-packages/mindspore/nn/loss/loss.py(519)/        if self.sparse:/#[CNode]78
}
# order:
#   1: ↓✓construct.20:[CNode]73{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Shape, [1]: Φlogits}
#   2: ↓✓construct.20:[CNode]74{[0]: ValueNode<DoSignaturePrimitive> S-Prim-negative, [1]: ValueNode<Int64Imm> 1}
#   3: ↓✓construct.20:[CNode]75{[0]: ValueNode<DoSignaturePrimitive> S-Prim-getitem, [1]: [CNode]73, [2]: [CNode]74}
#   4: ↓✓construct.20:labels{[0]: ValueNode<DoSignaturePrimitive> S-Prim-OneHot, [1]: labels, [2]: [CNode]75, [3]: ValueNode<Tensor> Tensor(shape=[], dtype=Float32, value= 1), [4]: ValueNode<Tensor> Tensor(shape=[], dtype=Float32, value= 0)}
#   5: ↓✓construct.20:[CNode]77{[0]: ValueNode<FuncGraph> ↓construct.76, [1]: labels}
#   6: ↓✓construct.20:[CNode]78{[0]: ValueNode<Primitive> Return, [1]: [CNode]77}


#===============================================================================
# num of function graphs in stack: 12
